{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sCPypR2VCDt",
    "outputId": "8129f8c0-8ef3-469d-c00e-a8de6a6a1eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bayesian-optimization in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.5.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "# Install Bayesian Optimization\n",
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "37l-9V9TTOk-",
    "outputId": "a0c2275e-a673-40be-e066-30a98ea8a612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "|   iter    |  target   | learni... | max_de... | n_esti... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.9177   \u001b[39m | \u001b[39m0.08116  \u001b[39m | \u001b[39m14.51    \u001b[39m | \u001b[39m79.9     \u001b[39m | \u001b[39m69.9     \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.8936   \u001b[39m | \u001b[39m0.03964  \u001b[39m | \u001b[39m6.56     \u001b[39m | \u001b[39m29.36    \u001b[39m | \u001b[39m89.96    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.914    \u001b[39m | \u001b[39m0.1242   \u001b[39m | \u001b[39m12.08    \u001b[39m | \u001b[39m26.54    \u001b[39m | \u001b[39m97.74    \u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m0.9244   \u001b[39m | \u001b[35m0.1682   \u001b[39m | \u001b[35m7.123    \u001b[39m | \u001b[35m38.64    \u001b[39m | \u001b[35m38.76    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.9188   \u001b[39m | \u001b[39m0.06781  \u001b[39m | \u001b[39m10.25    \u001b[39m | \u001b[39m57.4     \u001b[39m | \u001b[39m46.84    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.9201   \u001b[39m | \u001b[39m0.08779  \u001b[39m | \u001b[39m10.52    \u001b[39m | \u001b[39m57.71    \u001b[39m | \u001b[39m47.08    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.9153   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m14.3     \u001b[39m | \u001b[39m62.37    \u001b[39m | \u001b[39m50.69    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.9238   \u001b[39m | \u001b[39m0.172    \u001b[39m | \u001b[39m10.35    \u001b[39m | \u001b[39m35.02    \u001b[39m | \u001b[39m36.7     \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.9238   \u001b[39m | \u001b[39m0.1854   \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m32.71    \u001b[39m | \u001b[39m40.08    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.9128   \u001b[39m | \u001b[39m0.1157   \u001b[39m | \u001b[39m10.62    \u001b[39m | \u001b[39m35.5     \u001b[39m | \u001b[39m44.2     \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.9161   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m5.0      \u001b[39m | \u001b[39m35.41    \u001b[39m | \u001b[39m34.14    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.9163   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m11.48    \u001b[39m | \u001b[39m40.66    \u001b[39m | \u001b[39m36.01    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.8988   \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m8.916    \u001b[39m | \u001b[39m29.78    \u001b[39m | \u001b[39m37.78    \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.9146   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m6.953    \u001b[39m | \u001b[39m35.57    \u001b[39m | \u001b[39m38.91    \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.9195   \u001b[39m | \u001b[39m0.1452   \u001b[39m | \u001b[39m9.279    \u001b[39m | \u001b[39m37.71    \u001b[39m | \u001b[39m37.26    \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.9135   \u001b[39m | \u001b[39m0.08149  \u001b[39m | \u001b[39m7.056    \u001b[39m | \u001b[39m41.04    \u001b[39m | \u001b[39m38.52    \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.9157   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m11.96    \u001b[39m | \u001b[39m36.12    \u001b[39m | \u001b[39m35.71    \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.914    \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m8.602    \u001b[39m | \u001b[39m38.38    \u001b[39m | \u001b[39m40.08    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.9152   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m6.586    \u001b[39m | \u001b[39m38.2     \u001b[39m | \u001b[39m37.13    \u001b[39m |\n",
      "| \u001b[35m20       \u001b[39m | \u001b[35m0.9262   \u001b[39m | \u001b[35m0.1924   \u001b[39m | \u001b[35m9.035    \u001b[39m | \u001b[35m35.59    \u001b[39m | \u001b[35m35.94    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.8985   \u001b[39m | \u001b[39m0.01     \u001b[39m | \u001b[39m9.449    \u001b[39m | \u001b[39m34.28    \u001b[39m | \u001b[39m35.05    \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.9148   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m9.579    \u001b[39m | \u001b[39m35.69    \u001b[39m | \u001b[39m36.54    \u001b[39m |\n",
      "| \u001b[35m23       \u001b[39m | \u001b[35m0.9275   \u001b[39m | \u001b[35m0.1817   \u001b[39m | \u001b[35m11.92    \u001b[39m | \u001b[35m60.18    \u001b[39m | \u001b[35m34.08    \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.9193   \u001b[39m | \u001b[39m0.09899  \u001b[39m | \u001b[39m9.721    \u001b[39m | \u001b[39m97.06    \u001b[39m | \u001b[39m77.55    \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.9159   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m8.609    \u001b[39m | \u001b[39m35.82    \u001b[39m | \u001b[39m35.78    \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.9247   \u001b[39m | \u001b[39m0.09253  \u001b[39m | \u001b[39m11.89    \u001b[39m | \u001b[39m59.88    \u001b[39m | \u001b[39m34.28    \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.9249   \u001b[39m | \u001b[39m0.1577   \u001b[39m | \u001b[39m5.739    \u001b[39m | \u001b[39m87.71    \u001b[39m | \u001b[39m26.45    \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.9132   \u001b[39m | \u001b[39m0.06354  \u001b[39m | \u001b[39m10.52    \u001b[39m | \u001b[39m57.45    \u001b[39m | \u001b[39m47.09    \u001b[39m |\n",
      "| \u001b[35m29       \u001b[39m | \u001b[35m0.9315   \u001b[39m | \u001b[35m0.1923   \u001b[39m | \u001b[35m12.13    \u001b[39m | \u001b[35m60.27    \u001b[39m | \u001b[35m34.41    \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m0.9043   \u001b[39m | \u001b[39m0.05542  \u001b[39m | \u001b[39m14.92    \u001b[39m | \u001b[39m34.31    \u001b[39m | \u001b[39m48.77    \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m0.9113   \u001b[39m | \u001b[39m0.02852  \u001b[39m | \u001b[39m12.14    \u001b[39m | \u001b[39m97.89    \u001b[39m | \u001b[39m99.98    \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m0.8985   \u001b[39m | \u001b[39m0.0164   \u001b[39m | \u001b[39m11.83    \u001b[39m | \u001b[39m60.47    \u001b[39m | \u001b[39m34.49    \u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m0.8919   \u001b[39m | \u001b[39m0.02294  \u001b[39m | \u001b[39m8.611    \u001b[39m | \u001b[39m40.96    \u001b[39m | \u001b[39m46.85    \u001b[39m |\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m0.9028   \u001b[39m | \u001b[39m0.08634  \u001b[39m | \u001b[39m7.169    \u001b[39m | \u001b[39m26.84    \u001b[39m | \u001b[39m97.9     \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m0.9199   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m12.08    \u001b[39m | \u001b[39m60.12    \u001b[39m | \u001b[39m34.28    \u001b[39m |\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m0.9199   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m12.16    \u001b[39m | \u001b[39m60.34    \u001b[39m | \u001b[39m34.31    \u001b[39m |\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m0.9199   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m12.19    \u001b[39m | \u001b[39m60.2     \u001b[39m | \u001b[39m34.48    \u001b[39m |\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m0.888    \u001b[39m | \u001b[39m0.0341   \u001b[39m | \u001b[39m5.338    \u001b[39m | \u001b[39m26.33    \u001b[39m | \u001b[39m78.66    \u001b[39m |\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m0.9199   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m12.02    \u001b[39m | \u001b[39m60.25    \u001b[39m | \u001b[39m34.41    \u001b[39m |\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m0.9242   \u001b[39m | \u001b[39m0.08757  \u001b[39m | \u001b[39m12.14    \u001b[39m | \u001b[39m60.25    \u001b[39m | \u001b[39m34.39    \u001b[39m |\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m0.9115   \u001b[39m | \u001b[39m0.04483  \u001b[39m | \u001b[39m6.397    \u001b[39m | \u001b[39m62.35    \u001b[39m | \u001b[39m48.86    \u001b[39m |\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m0.917    \u001b[39m | \u001b[39m0.03667  \u001b[39m | \u001b[39m11.91    \u001b[39m | \u001b[39m73.79    \u001b[39m | \u001b[39m32.86    \u001b[39m |\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m0.9227   \u001b[39m | \u001b[39m0.1828   \u001b[39m | \u001b[39m12.15    \u001b[39m | \u001b[39m60.36    \u001b[39m | \u001b[39m34.47    \u001b[39m |\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m0.9199   \u001b[39m | \u001b[39m0.2      \u001b[39m | \u001b[39m12.22    \u001b[39m | \u001b[39m60.21    \u001b[39m | \u001b[39m34.34    \u001b[39m |\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m0.9254   \u001b[39m | \u001b[39m0.1903   \u001b[39m | \u001b[39m13.06    \u001b[39m | \u001b[39m56.9     \u001b[39m | \u001b[39m82.17    \u001b[39m |\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m0.9209   \u001b[39m | \u001b[39m0.06671  \u001b[39m | \u001b[39m9.787    \u001b[39m | \u001b[39m96.84    \u001b[39m | \u001b[39m77.52    \u001b[39m |\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m0.9194   \u001b[39m | \u001b[39m0.08571  \u001b[39m | \u001b[39m13.9     \u001b[39m | \u001b[39m60.19    \u001b[39m | \u001b[39m74.18    \u001b[39m |\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m0.9045   \u001b[39m | \u001b[39m0.01988  \u001b[39m | \u001b[39m12.89    \u001b[39m | \u001b[39m95.59    \u001b[39m | \u001b[39m52.01    \u001b[39m |\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m0.9234   \u001b[39m | \u001b[39m0.1865   \u001b[39m | \u001b[39m12.74    \u001b[39m | \u001b[39m73.26    \u001b[39m | \u001b[39m97.02    \u001b[39m |\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m0.9175   \u001b[39m | \u001b[39m0.09886  \u001b[39m | \u001b[39m14.01    \u001b[39m | \u001b[39m60.02    \u001b[39m | \u001b[39m74.31    \u001b[39m |\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m0.8909   \u001b[39m | \u001b[39m0.0103   \u001b[39m | \u001b[39m9.804    \u001b[39m | \u001b[39m96.96    \u001b[39m | \u001b[39m77.36    \u001b[39m |\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m0.9281   \u001b[39m | \u001b[39m0.1605   \u001b[39m | \u001b[39m5.245    \u001b[39m | \u001b[39m73.8     \u001b[39m | \u001b[39m32.74    \u001b[39m |\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m0.9209   \u001b[39m | \u001b[39m0.08505  \u001b[39m | \u001b[39m12.29    \u001b[39m | \u001b[39m60.34    \u001b[39m | \u001b[39m34.43    \u001b[39m |\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m0.9239   \u001b[39m | \u001b[39m0.1553   \u001b[39m | \u001b[39m5.205    \u001b[39m | \u001b[39m73.85    \u001b[39m | \u001b[39m32.63    \u001b[39m |\n",
      "| \u001b[35m55       \u001b[39m | \u001b[35m0.9375   \u001b[39m | \u001b[35m0.1957   \u001b[39m | \u001b[35m10.15    \u001b[39m | \u001b[35m52.24    \u001b[39m | \u001b[35m29.27    \u001b[39m |\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m0.9325   \u001b[39m | \u001b[39m0.1982   \u001b[39m | \u001b[39m10.15    \u001b[39m | \u001b[39m52.24    \u001b[39m | \u001b[39m29.28    \u001b[39m |\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m0.8988   \u001b[39m | \u001b[39m0.02107  \u001b[39m | \u001b[39m12.64    \u001b[39m | \u001b[39m73.23    \u001b[39m | \u001b[39m96.92    \u001b[39m |\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m0.9202   \u001b[39m | \u001b[39m0.1675   \u001b[39m | \u001b[39m6.937    \u001b[39m | \u001b[39m65.75    \u001b[39m | \u001b[39m89.02    \u001b[39m |\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m0.9205   \u001b[39m | \u001b[39m0.1776   \u001b[39m | \u001b[39m9.684    \u001b[39m | \u001b[39m26.7     \u001b[39m | \u001b[39m35.31    \u001b[39m |\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m0.9212   \u001b[39m | \u001b[39m0.07796  \u001b[39m | \u001b[39m13.5     \u001b[39m | \u001b[39m92.29    \u001b[39m | \u001b[39m97.38    \u001b[39m |\n",
      "| \u001b[39m61       \u001b[39m | \u001b[39m0.9239   \u001b[39m | \u001b[39m0.1887   \u001b[39m | \u001b[39m12.72    \u001b[39m | \u001b[39m73.45    \u001b[39m | \u001b[39m97.06    \u001b[39m |\n",
      "| \u001b[39m62       \u001b[39m | \u001b[39m0.9272   \u001b[39m | \u001b[39m0.1768   \u001b[39m | \u001b[39m12.09    \u001b[39m | \u001b[39m98.28    \u001b[39m | \u001b[39m25.9     \u001b[39m |\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m0.9219   \u001b[39m | \u001b[39m0.1091   \u001b[39m | \u001b[39m12.47    \u001b[39m | \u001b[39m68.77    \u001b[39m | \u001b[39m74.74    \u001b[39m |\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m0.9015   \u001b[39m | \u001b[39m0.01705  \u001b[39m | \u001b[39m8.261    \u001b[39m | \u001b[39m96.46    \u001b[39m | \u001b[39m66.23    \u001b[39m |\n",
      "| \u001b[39m65       \u001b[39m | \u001b[39m0.9191   \u001b[39m | \u001b[39m0.1624   \u001b[39m | \u001b[39m13.05    \u001b[39m | \u001b[39m27.69    \u001b[39m | \u001b[39m34.96    \u001b[39m |\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m0.9261   \u001b[39m | \u001b[39m0.1219   \u001b[39m | \u001b[39m12.07    \u001b[39m | \u001b[39m83.61    \u001b[39m | \u001b[39m35.38    \u001b[39m |\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m0.9228   \u001b[39m | \u001b[39m0.1217   \u001b[39m | \u001b[39m12.63    \u001b[39m | \u001b[39m73.58    \u001b[39m | \u001b[39m97.02    \u001b[39m |\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m0.9186   \u001b[39m | \u001b[39m0.1323   \u001b[39m | \u001b[39m14.72    \u001b[39m | \u001b[39m40.52    \u001b[39m | \u001b[39m91.22    \u001b[39m |\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m0.922    \u001b[39m | \u001b[39m0.199    \u001b[39m | \u001b[39m12.86    \u001b[39m | \u001b[39m27.63    \u001b[39m | \u001b[39m34.92    \u001b[39m |\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m0.9192   \u001b[39m | \u001b[39m0.1337   \u001b[39m | \u001b[39m7.721    \u001b[39m | \u001b[39m37.63    \u001b[39m | \u001b[39m90.71    \u001b[39m |\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m0.9221   \u001b[39m | \u001b[39m0.1517   \u001b[39m | \u001b[39m10.83    \u001b[39m | \u001b[39m72.48    \u001b[39m | \u001b[39m75.47    \u001b[39m |\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m0.9296   \u001b[39m | \u001b[39m0.092    \u001b[39m | \u001b[39m9.447    \u001b[39m | \u001b[39m84.54    \u001b[39m | \u001b[39m29.8     \u001b[39m |\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m0.8967   \u001b[39m | \u001b[39m0.02073  \u001b[39m | \u001b[39m8.124    \u001b[39m | \u001b[39m64.87    \u001b[39m | \u001b[39m84.05    \u001b[39m |\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m0.9208   \u001b[39m | \u001b[39m0.05653  \u001b[39m | \u001b[39m5.412    \u001b[39m | \u001b[39m87.06    \u001b[39m | \u001b[39m39.67    \u001b[39m |\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m0.9192   \u001b[39m | \u001b[39m0.1585   \u001b[39m | \u001b[39m7.693    \u001b[39m | \u001b[39m33.5     \u001b[39m | \u001b[39m39.56    \u001b[39m |\n",
      "| \u001b[39m76       \u001b[39m | \u001b[39m0.9165   \u001b[39m | \u001b[39m0.1046   \u001b[39m | \u001b[39m9.965    \u001b[39m | \u001b[39m61.74    \u001b[39m | \u001b[39m91.05    \u001b[39m |\n",
      "| \u001b[39m77       \u001b[39m | \u001b[39m0.9224   \u001b[39m | \u001b[39m0.129    \u001b[39m | \u001b[39m10.39    \u001b[39m | \u001b[39m69.04    \u001b[39m | \u001b[39m60.69    \u001b[39m |\n",
      "| \u001b[39m78       \u001b[39m | \u001b[39m0.911    \u001b[39m | \u001b[39m0.0464   \u001b[39m | \u001b[39m9.443    \u001b[39m | \u001b[39m67.45    \u001b[39m | \u001b[39m59.07    \u001b[39m |\n",
      "| \u001b[39m79       \u001b[39m | \u001b[39m0.921    \u001b[39m | \u001b[39m0.1899   \u001b[39m | \u001b[39m10.61    \u001b[39m | \u001b[39m69.1     \u001b[39m | \u001b[39m60.78    \u001b[39m |\n",
      "| \u001b[39m80       \u001b[39m | \u001b[39m0.92     \u001b[39m | \u001b[39m0.07882  \u001b[39m | \u001b[39m9.545    \u001b[39m | \u001b[39m62.22    \u001b[39m | \u001b[39m64.77    \u001b[39m |\n",
      "| \u001b[39m81       \u001b[39m | \u001b[39m0.9219   \u001b[39m | \u001b[39m0.08543  \u001b[39m | \u001b[39m9.744    \u001b[39m | \u001b[39m97.07    \u001b[39m | \u001b[39m77.54    \u001b[39m |\n",
      "| \u001b[39m82       \u001b[39m | \u001b[39m0.9233   \u001b[39m | \u001b[39m0.1855   \u001b[39m | \u001b[39m14.0     \u001b[39m | \u001b[39m46.51    \u001b[39m | \u001b[39m42.2     \u001b[39m |\n",
      "| \u001b[39m83       \u001b[39m | \u001b[39m0.9168   \u001b[39m | \u001b[39m0.09468  \u001b[39m | \u001b[39m7.811    \u001b[39m | \u001b[39m41.77    \u001b[39m | \u001b[39m38.77    \u001b[39m |\n",
      "| \u001b[39m84       \u001b[39m | \u001b[39m0.9178   \u001b[39m | \u001b[39m0.1211   \u001b[39m | \u001b[39m13.76    \u001b[39m | \u001b[39m34.54    \u001b[39m | \u001b[39m47.89    \u001b[39m |\n",
      "| \u001b[39m85       \u001b[39m | \u001b[39m0.9316   \u001b[39m | \u001b[39m0.1936   \u001b[39m | \u001b[39m10.24    \u001b[39m | \u001b[39m93.75    \u001b[39m | \u001b[39m41.27    \u001b[39m |\n",
      "| \u001b[39m86       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m0.08335  \u001b[39m | \u001b[39m6.804    \u001b[39m | \u001b[39m80.14    \u001b[39m | \u001b[39m64.89    \u001b[39m |\n",
      "| \u001b[39m87       \u001b[39m | \u001b[39m0.9016   \u001b[39m | \u001b[39m0.03069  \u001b[39m | \u001b[39m6.583    \u001b[39m | \u001b[39m56.26    \u001b[39m | \u001b[39m55.14    \u001b[39m |\n",
      "| \u001b[39m88       \u001b[39m | \u001b[39m0.9039   \u001b[39m | \u001b[39m0.08333  \u001b[39m | \u001b[39m9.654    \u001b[39m | \u001b[39m28.1     \u001b[39m | \u001b[39m92.14    \u001b[39m |\n",
      "| \u001b[39m89       \u001b[39m | \u001b[39m0.9117   \u001b[39m | \u001b[39m0.02436  \u001b[39m | \u001b[39m12.93    \u001b[39m | \u001b[39m68.24    \u001b[39m | \u001b[39m25.75    \u001b[39m |\n",
      "| \u001b[39m90       \u001b[39m | \u001b[39m0.9312   \u001b[39m | \u001b[39m0.1714   \u001b[39m | \u001b[39m9.334    \u001b[39m | \u001b[39m52.32    \u001b[39m | \u001b[39m31.14    \u001b[39m |\n",
      "| \u001b[39m91       \u001b[39m | \u001b[39m0.9043   \u001b[39m | \u001b[39m0.04435  \u001b[39m | \u001b[39m7.29     \u001b[39m | \u001b[39m28.7     \u001b[39m | \u001b[39m35.8     \u001b[39m |\n",
      "| \u001b[39m92       \u001b[39m | \u001b[39m0.8994   \u001b[39m | \u001b[39m0.01042  \u001b[39m | \u001b[39m11.37    \u001b[39m | \u001b[39m94.6     \u001b[39m | \u001b[39m33.59    \u001b[39m |\n",
      "| \u001b[39m93       \u001b[39m | \u001b[39m0.9215   \u001b[39m | \u001b[39m0.1597   \u001b[39m | \u001b[39m7.771    \u001b[39m | \u001b[39m41.72    \u001b[39m | \u001b[39m38.86    \u001b[39m |\n",
      "| \u001b[39m94       \u001b[39m | \u001b[39m0.9226   \u001b[39m | \u001b[39m0.08682  \u001b[39m | \u001b[39m12.14    \u001b[39m | \u001b[39m60.25    \u001b[39m | \u001b[39m34.41    \u001b[39m |\n",
      "| \u001b[39m95       \u001b[39m | \u001b[39m0.9214   \u001b[39m | \u001b[39m0.1648   \u001b[39m | \u001b[39m9.018    \u001b[39m | \u001b[39m35.41    \u001b[39m | \u001b[39m35.92    \u001b[39m |\n",
      "| \u001b[39m96       \u001b[39m | \u001b[39m0.9165   \u001b[39m | \u001b[39m0.1999   \u001b[39m | \u001b[39m7.962    \u001b[39m | \u001b[39m98.01    \u001b[39m | \u001b[39m56.47    \u001b[39m |\n",
      "| \u001b[39m97       \u001b[39m | \u001b[39m0.9232   \u001b[39m | \u001b[39m0.1266   \u001b[39m | \u001b[39m12.81    \u001b[39m | \u001b[39m57.5     \u001b[39m | \u001b[39m96.58    \u001b[39m |\n",
      "| \u001b[39m98       \u001b[39m | \u001b[39m0.9178   \u001b[39m | \u001b[39m0.1806   \u001b[39m | \u001b[39m7.832    \u001b[39m | \u001b[39m82.91    \u001b[39m | \u001b[39m56.87    \u001b[39m |\n",
      "| \u001b[39m99       \u001b[39m | \u001b[39m0.8938   \u001b[39m | \u001b[39m0.02217  \u001b[39m | \u001b[39m5.773    \u001b[39m | \u001b[39m55.05    \u001b[39m | \u001b[39m59.28    \u001b[39m |\n",
      "| \u001b[39m100      \u001b[39m | \u001b[39m0.9302   \u001b[39m | \u001b[39m0.1317   \u001b[39m | \u001b[39m12.06    \u001b[39m | \u001b[39m60.34    \u001b[39m | \u001b[39m34.09    \u001b[39m |\n",
      "| \u001b[39m101      \u001b[39m | \u001b[39m0.9126   \u001b[39m | \u001b[39m0.02281  \u001b[39m | \u001b[39m14.99    \u001b[39m | \u001b[39m99.74    \u001b[39m | \u001b[39m33.64    \u001b[39m |\n",
      "| \u001b[39m102      \u001b[39m | \u001b[39m0.9175   \u001b[39m | \u001b[39m0.1582   \u001b[39m | \u001b[39m6.832    \u001b[39m | \u001b[39m46.67    \u001b[39m | \u001b[39m85.92    \u001b[39m |\n",
      "| \u001b[39m103      \u001b[39m | \u001b[39m0.9167   \u001b[39m | \u001b[39m0.07728  \u001b[39m | \u001b[39m7.14     \u001b[39m | \u001b[39m65.67    \u001b[39m | \u001b[39m88.89    \u001b[39m |\n",
      "| \u001b[39m104      \u001b[39m | \u001b[39m0.9195   \u001b[39m | \u001b[39m0.1776   \u001b[39m | \u001b[39m10.04    \u001b[39m | \u001b[39m48.31    \u001b[39m | \u001b[39m64.92    \u001b[39m |\n",
      "| \u001b[39m105      \u001b[39m | \u001b[39m0.9152   \u001b[39m | \u001b[39m0.1366   \u001b[39m | \u001b[39m9.513    \u001b[39m | \u001b[39m26.56    \u001b[39m | \u001b[39m35.41    \u001b[39m |\n",
      "| \u001b[39m106      \u001b[39m | \u001b[39m0.9288   \u001b[39m | \u001b[39m0.127    \u001b[39m | \u001b[39m5.833    \u001b[39m | \u001b[39m87.7     \u001b[39m | \u001b[39m26.53    \u001b[39m |\n",
      "| \u001b[39m107      \u001b[39m | \u001b[39m0.903    \u001b[39m | \u001b[39m0.06107  \u001b[39m | \u001b[39m14.77    \u001b[39m | \u001b[39m28.43    \u001b[39m | \u001b[39m57.38    \u001b[39m |\n",
      "| \u001b[39m108      \u001b[39m | \u001b[39m0.9011   \u001b[39m | \u001b[39m0.03933  \u001b[39m | \u001b[39m9.565    \u001b[39m | \u001b[39m44.01    \u001b[39m | \u001b[39m89.96    \u001b[39m |\n",
      "| \u001b[39m109      \u001b[39m | \u001b[39m0.9142   \u001b[39m | \u001b[39m0.1558   \u001b[39m | \u001b[39m14.39    \u001b[39m | \u001b[39m42.32    \u001b[39m | \u001b[39m62.58    \u001b[39m |\n",
      "| \u001b[39m110      \u001b[39m | \u001b[39m0.9318   \u001b[39m | \u001b[39m0.118    \u001b[39m | \u001b[39m10.09    \u001b[39m | \u001b[39m52.25    \u001b[39m | \u001b[39m29.19    \u001b[39m |\n",
      "| \u001b[39m111      \u001b[39m | \u001b[39m0.934    \u001b[39m | \u001b[39m0.1925   \u001b[39m | \u001b[39m11.84    \u001b[39m | \u001b[39m60.11    \u001b[39m | \u001b[39m33.88    \u001b[39m |\n",
      "| \u001b[39m112      \u001b[39m | \u001b[39m0.9246   \u001b[39m | \u001b[39m0.1096   \u001b[39m | \u001b[39m6.234    \u001b[39m | \u001b[39m59.5     \u001b[39m | \u001b[39m81.63    \u001b[39m |\n",
      "| \u001b[39m113      \u001b[39m | \u001b[39m0.9058   \u001b[39m | \u001b[39m0.04294  \u001b[39m | \u001b[39m13.05    \u001b[39m | \u001b[39m56.99    \u001b[39m | \u001b[39m82.0     \u001b[39m |\n",
      "| \u001b[39m114      \u001b[39m | \u001b[39m0.9177   \u001b[39m | \u001b[39m0.09207  \u001b[39m | \u001b[39m10.21    \u001b[39m | \u001b[39m57.39    \u001b[39m | \u001b[39m46.84    \u001b[39m |\n",
      "| \u001b[39m115      \u001b[39m | \u001b[39m0.9302   \u001b[39m | \u001b[39m0.1924   \u001b[39m | \u001b[39m11.07    \u001b[39m | \u001b[39m65.48    \u001b[39m | \u001b[39m47.6     \u001b[39m |\n",
      "| \u001b[39m116      \u001b[39m | \u001b[39m0.9106   \u001b[39m | \u001b[39m0.04735  \u001b[39m | \u001b[39m11.07    \u001b[39m | \u001b[39m61.25    \u001b[39m | \u001b[39m76.4     \u001b[39m |\n",
      "| \u001b[39m117      \u001b[39m | \u001b[39m0.9134   \u001b[39m | \u001b[39m0.05799  \u001b[39m | \u001b[39m10.27    \u001b[39m | \u001b[39m68.99    \u001b[39m | \u001b[39m60.72    \u001b[39m |\n",
      "| \u001b[39m118      \u001b[39m | \u001b[39m0.9033   \u001b[39m | \u001b[39m0.01485  \u001b[39m | \u001b[39m5.069    \u001b[39m | \u001b[39m73.74    \u001b[39m | \u001b[39m32.73    \u001b[39m |\n",
      "| \u001b[39m119      \u001b[39m | \u001b[39m0.9162   \u001b[39m | \u001b[39m0.1222   \u001b[39m | \u001b[39m6.518    \u001b[39m | \u001b[39m33.58    \u001b[39m | \u001b[39m95.9     \u001b[39m |\n",
      "| \u001b[39m120      \u001b[39m | \u001b[39m0.923    \u001b[39m | \u001b[39m0.173    \u001b[39m | \u001b[39m5.409    \u001b[39m | \u001b[39m91.23    \u001b[39m | \u001b[39m85.67    \u001b[39m |\n",
      "| \u001b[39m121      \u001b[39m | \u001b[39m0.9114   \u001b[39m | \u001b[39m0.04564  \u001b[39m | \u001b[39m11.09    \u001b[39m | \u001b[39m65.52    \u001b[39m | \u001b[39m47.63    \u001b[39m |\n",
      "| \u001b[39m122      \u001b[39m | \u001b[39m0.9188   \u001b[39m | \u001b[39m0.1539   \u001b[39m | \u001b[39m10.43    \u001b[39m | \u001b[39m69.14    \u001b[39m | \u001b[39m60.56    \u001b[39m |\n",
      "| \u001b[39m123      \u001b[39m | \u001b[39m0.8874   \u001b[39m | \u001b[39m0.0147   \u001b[39m | \u001b[39m12.86    \u001b[39m | \u001b[39m36.2     \u001b[39m | \u001b[39m49.81    \u001b[39m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b23758231bad>\u001b[0m in \u001b[0;36m<cell line: 124>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;31m# Perform Bayesian Optimization with 1280 iterations (which tests 2560 models due to the even-number rounding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1280\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Get the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 \u001b[0mx_probe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b23758231bad>\u001b[0m in \u001b[0;36mbayes_optimization\u001b[0;34m(n_estimators_rf, max_depth_rf, n_estimators_gb, learning_rate_gb)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mstacking_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0m_raise_for_unsupported_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             predictions = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    265\u001b[0m                 delayed(cross_val_predict)(\n\u001b[1;32m    266\u001b[0m                     \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv('/content/drive/My Drive/drugdata.csv')\n",
    "df = df.iloc[:,:6].dropna()\n",
    "X = df.iloc[:, :5]\n",
    "y = df.iloc[:, 5]\n",
    "d = 1000000\n",
    "\n",
    "# Split data: 64% train, 16% val, 20% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)  # 0.2 of 80% = 16%\n",
    "\n",
    "# Scale data\n",
    "scaler_X = MinMaxScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Evaluation metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rrmse = rmse / (np.max(y_true) - np.min(y_true))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    aapre = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    rae = np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true - np.mean(y_true)))\n",
    "    return mae, mse, rmse, rrmse, r2, aapre, rae\n",
    "\n",
    "# Bayesian Optimization target function (uses validation set!)\n",
    "def bayes_optimization(n_estimators_rf, max_depth_rf, n_estimators_gb, learning_rate_gb):\n",
    "    # Round & scale hyperparameters\n",
    "    n_estimators_rf = int(n_estimators_rf) * 2\n",
    "    max_depth_rf = int(max_depth_rf) * 2\n",
    "    n_estimators_gb = int(n_estimators_gb) * 2\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators_rf, max_depth=max_depth_rf, random_state=42)\n",
    "    gb = GradientBoostingRegressor(n_estimators=n_estimators_gb, learning_rate=learning_rate_gb, random_state=42)\n",
    "\n",
    "    stacking_model = StackingRegressor(\n",
    "        estimators=[('rf', rf), ('gb', gb)],\n",
    "        final_estimator=Ridge(),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    stacking_model.fit(X_train_scaled, y_train_scaled)\n",
    "    y_val_pred = stacking_model.predict(X_val_scaled)\n",
    "\n",
    "    return r2_score(y_val_scaled, y_val_pred)\n",
    "\n",
    "# Hyperparameter bounds\n",
    "pbounds = {\n",
    "    'n_estimators_rf': (25, 100),\n",
    "    'max_depth_rf': (5, 15),\n",
    "    'n_estimators_gb': (25, 100),\n",
    "    'learning_rate_gb': (0.01, 0.2)\n",
    "}\n",
    "\n",
    "# Run Bayesian Optimization\n",
    "optimizer = BayesianOptimization(\n",
    "    f=bayes_optimization,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "optimizer.maximize(init_points=5, n_iter=100)\n",
    "\n",
    "# Best parameters\n",
    "best_params = optimizer.max['params']\n",
    "best_base_models = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=int(best_params['n_estimators_rf']) * 2,\n",
    "                                 max_depth=int(best_params['max_depth_rf']) * 2,\n",
    "                                 random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=int(best_params['n_estimators_gb']) * 2,\n",
    "                                     learning_rate=best_params['learning_rate_gb'],\n",
    "                                     random_state=42))\n",
    "]\n",
    "\n",
    "# Retrain on full train + validation set\n",
    "X_trainval_scaled = scaler_X.fit_transform(pd.concat([X_train, X_val]))\n",
    "y_trainval_scaled = scaler_y.fit_transform(pd.concat([y_train, y_val]).values.reshape(-1, 1)).flatten()\n",
    "\n",
    "best_stacking_model = StackingRegressor(\n",
    "    estimators=best_base_models,\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "\n",
    "best_stacking_model.fit(X_trainval_scaled, y_trainval_scaled)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred_scaled = best_stacking_model.predict(scaler_X.transform(X_test))\n",
    "y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_true = y_test.values\n",
    "\n",
    "# Final metrics\n",
    "test_mae, test_mse, test_rmse, test_rrmse, test_r2, test_aapre, test_rae = calculate_metrics(y_test_true / d, y_test_pred / d)\n",
    "\n",
    "# Print results\n",
    "print(\"\\n--- Final Evaluation on Test Set ---\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"Test RRMSE: {test_rrmse:.4f}\")\n",
    "print(f\"Test R²: {test_r2:.4f}\")\n",
    "print(f\"Test AAPRE: {test_aapre:.4f}%\")\n",
    "print(f\"Test RAE: {test_rae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZpiUV9Cq_0rN",
    "outputId": "034ddea8-46bf-426d-b12b-8cf2a7404b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-649996c1983f>:34: RuntimeWarning: divide by zero encountered in divide\n",
      "  aapre = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
      "<ipython-input-1-649996c1983f>:34: RuntimeWarning: divide by zero encountered in divide\n",
      "  aapre = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
      "<ipython-input-1-649996c1983f>:34: RuntimeWarning: divide by zero encountered in divide\n",
      "  aapre = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics Across Folds:\n",
      "fold           2.500000e+00\n",
      "train_mae      2.255797e-04\n",
      "train_mse      2.045773e-07\n",
      "train_rmse     4.470136e-04\n",
      "train_rrmse    4.815856e+02\n",
      "train_r2      -2.508579e+07\n",
      "train_aapre             inf\n",
      "train_rae      5.144466e+03\n",
      "test_mae       2.223443e-04\n",
      "test_mse       1.692787e-07\n",
      "test_rmse      4.107105e-04\n",
      "test_rrmse     5.632285e+02\n",
      "test_r2       -2.544133e+07\n",
      "test_aapre              inf\n",
      "test_rae       5.332296e+03\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-649996c1983f>:34: RuntimeWarning: divide by zero encountered in divide\n",
      "  aapre = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n"
     ]
    }
   ],
   "source": [
    "#Performing cross-validation on the selected model\n",
    "# Import necessary libraries\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('/content/drive/My Drive/drugdata.csv')\n",
    "X = df.iloc[:, :5]\n",
    "y = df.iloc[:, 5]\n",
    "d = 1000000\n",
    "\n",
    "# Scale the data\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Function to calculate evaluation metrics including RAE\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    rrmse = rmse / (np.max(y_true) - np.min(y_true))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    aapre = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "    # RAE calculation\n",
    "    rae = np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true - np.mean(y_true)))\n",
    "\n",
    "    return mae, mse, rmse, rrmse, r2, aapre, rae\n",
    "\n",
    "# Define base models for the stacking ensemble with specified hyperparameters\n",
    "base_models = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)),\n",
    "    ('gb', GradientBoostingRegressor(n_estimators=200, learning_rate=0.2, random_state=42))\n",
    "]\n",
    "\n",
    "# Define the stacking ensemble with a Ridge regression meta-model\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=Ridge()\n",
    ")\n",
    "\n",
    "# Set up 4-fold cross-validation\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# List to store all metrics for each fold\n",
    "all_metrics = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_scaled), 1):\n",
    "    # Split data according to the current fold\n",
    "    X_train_fold, X_test_fold = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train_fold, y_test_fold = y_scaled[train_index], y_scaled[test_index]\n",
    "\n",
    "    # Fit the stacking model\n",
    "    stacking_model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred_scaled_fold = stacking_model.predict(X_train_fold)\n",
    "    y_test_pred_scaled_fold = stacking_model.predict(X_test_fold)\n",
    "\n",
    "    # Denormalize the predictions\n",
    "    y_train_pred_fold = scaler_y.inverse_transform(y_train_pred_scaled_fold.reshape(-1, 1)).flatten()\n",
    "    y_test_pred_fold = scaler_y.inverse_transform(y_test_pred_scaled_fold.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Calculate metrics for training and testing sets\n",
    "    train_mae, train_mse, train_rmse, train_rrmse, train_r2, train_aapre, train_rae = calculate_metrics(y_train_fold / d, y_train_pred_fold / d)\n",
    "    test_mae, test_mse, test_rmse, test_rrmse, test_r2, test_aapre, test_rae = calculate_metrics(y_test_fold / d, y_test_pred_fold / d)\n",
    "\n",
    "    # Store metrics for this fold\n",
    "    all_metrics.append({\n",
    "        'fold': fold,\n",
    "        'train_mae': train_mae, 'train_mse': train_mse, 'train_rmse': train_rmse,\n",
    "        'train_rrmse': train_rrmse, 'train_r2': train_r2, 'train_aapre': train_aapre, 'train_rae': train_rae,\n",
    "        'test_mae': test_mae, 'test_mse': test_mse, 'test_rmse': test_rmse,\n",
    "        'test_rrmse': test_rrmse, 'test_r2': test_r2, 'test_aapre': test_aapre, 'test_rae': test_rae\n",
    "    })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame for easier analysis\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "\n",
    "# Calculate the mean of the metrics across all folds\n",
    "mean_metrics = metrics_df.mean()\n",
    "print(\"Average Metrics Across Folds:\")\n",
    "print(mean_metrics)\n",
    "\n",
    "# # Optionally, save the metrics to a CSV file\n",
    "# metrics_df.to_csv('/content/drive/My Drive/stacking_model_cv_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dthmjQvwBCSf",
    "outputId": "ee4a5197-b95a-45c5-dd0e-378c0b9f12fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fold': 1,\n",
       "  'train_mae': 0.0002542388945143164,\n",
       "  'train_mse': 2.7821935253254157e-07,\n",
       "  'train_rmse': 0.0005274650249377125,\n",
       "  'train_rrmse': 527.4650249377124,\n",
       "  'train_r2': -30013568.45729348,\n",
       "  'train_aapre': inf,\n",
       "  'train_rae': 5395.652058613807,\n",
       "  'test_mae': 0.00022630908598068525,\n",
       "  'test_mse': 1.6156643806920122e-07,\n",
       "  'test_rmse': 0.00040195327846554655,\n",
       "  'test_rrmse': 695.9002632965554,\n",
       "  'test_r2': -39819711.96613975,\n",
       "  'test_aapre': 9011516.62121235,\n",
       "  'test_rae': 6739.682671462682},\n",
       " {'fold': 2,\n",
       "  'train_mae': 0.00023890046161613272,\n",
       "  'train_mse': 2.3578945021082066e-07,\n",
       "  'train_rmse': 0.0004855815587631193,\n",
       "  'train_rrmse': 485.5815587631193,\n",
       "  'train_r2': -26323626.63345711,\n",
       "  'train_aapre': inf,\n",
       "  'train_rae': 5094.763406152443,\n",
       "  'test_mae': 0.00020043082571533164,\n",
       "  'test_mse': 1.4050279391364615e-07,\n",
       "  'test_rmse': 0.0003748370231362507,\n",
       "  'test_rrmse': 551.3096895573537,\n",
       "  'test_r2': -28206642.70280763,\n",
       "  'test_aapre': 14938608.624251941,\n",
       "  'test_rae': 5837.601674537998},\n",
       " {'fold': 3,\n",
       "  'train_mae': 0.0002222485022841296,\n",
       "  'train_mse': 1.8672954822876891e-07,\n",
       "  'train_rmse': 0.000432122145033981,\n",
       "  'train_rrmse': 570.4046885084417,\n",
       "  'train_r2': -25170567.447972406,\n",
       "  'train_aapre': inf,\n",
       "  'train_rae': 5233.5969416786365,\n",
       "  'test_mae': 0.00023200083560710434,\n",
       "  'test_mse': 1.8461610830872962e-07,\n",
       "  'test_rmse': 0.0004296697665751334,\n",
       "  'test_rrmse': 429.67627694505626,\n",
       "  'test_r2': -19128086.069334373,\n",
       "  'test_aapre': 11526759.325707167,\n",
       "  'test_rae': 4878.916465070246},\n",
       " {'fold': 4,\n",
       "  'train_mae': 0.00018693079883810016,\n",
       "  'train_mse': 1.1757064923741971e-07,\n",
       "  'train_rmse': 0.00034288576703826555,\n",
       "  'train_rrmse': 342.8909624542766,\n",
       "  'train_r2': -18835406.2410688,\n",
       "  'train_aapre': 11630721.487299267,\n",
       "  'train_rae': 4853.851718439243,\n",
       "  'test_mae': 0.00023063653548396605,\n",
       "  'test_mse': 1.9042933834535008e-07,\n",
       "  'test_rmse': 0.000436382101311855,\n",
       "  'test_rrmse': 576.0278648757376,\n",
       "  'test_r2': -14610868.923545465,\n",
       "  'test_aapre': inf,\n",
       "  'test_rae': 3872.98365183533}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
